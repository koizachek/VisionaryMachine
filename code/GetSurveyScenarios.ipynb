{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1671796b",
   "metadata": {},
   "source": [
    "# Create a subset for the survey from all scenario types in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['human_scenarios.xlsx', 'gpt3_scenarios.xlsx', 'gpt35_scenarios.xlsx', 'gpt4_scenarios.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a56326",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c939443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each CSV file: I want to have 2 scenarios from 2030, two from 2040 and 1 from 2050\n",
    "for file in files:\n",
    "    df = pd.read_excel(file)\n",
    "\n",
    "    # separate the scenarios by years\n",
    "    df_2030 = df[(df['year'] == 2030) & (df['keyword'] == 'ecology')]\n",
    "    df_2040 = df[(df['year'] == 2040) & (df['keyword'] == 'ecology')]\n",
    "    df_2050 = df[(df['year'] == 2050) & (df['keyword'] == 'ecology')]\n",
    "    \n",
    "    num_2030_sentences = 2\n",
    "    num_2040_sentences = 2\n",
    "    num_2050_sentences = 2\n",
    "    \n",
    "    # sample the scenarios for each specified year\n",
    "    subset_2030 = df_2030.sample(n=num_2030_sentences, replace=False, random_state=10)[['year', 'scenario']]\n",
    "    subset_2040 = df_2040.sample(n=num_2040_sentences, replace=False, random_state=13)[['year', 'scenario']]\n",
    "    subset_2050 = df_2050.sample(n=num_2050_sentences, replace=False, random_state=15)[['year', 'scenario']]\n",
    "    \n",
    "    # concatenate the subsets of different years\n",
    "    subset = pd.concat([subset_2030, subset_2040, subset_2050], axis=0, ignore_index=True)\n",
    "\n",
    "    # add the source column with the current file name\n",
    "    subset['source'] = file\n",
    "    \n",
    "    # add the subset of sentences to the list\n",
    "    subsets.append(subset)\n",
    "\n",
    "# combine the subsets of sentences into a single DataFrame\n",
    "combined_df = pd.concat(subsets, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the subsets of sentences into a single DataFrame\n",
    "combined_df = pd.concat(subsets, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['scenario']=combined_df['scenario'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#combined_df.to_excel('delphidata.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568890f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
