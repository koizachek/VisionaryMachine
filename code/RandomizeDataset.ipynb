{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9355a0a5",
   "metadata": {},
   "source": [
    "# Create a subset of the human-made scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913374e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../Szenario/Scenarios2030.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e32d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentences = 552\n",
    "subset = df.sample(n=num_sentences, replace=False, random_state=49)[['year','scenario', 'keyword']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(subset, columns=['year','scenario', 'keyword'])\n",
    "#new_df.to_csv('random_human_scenarios2030.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94134c4",
   "metadata": {},
   "source": [
    "# check how topics/years are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../Szenario/humansc_tofinetune.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of sentences in each year\n",
    "counts = df['year'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a904c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of sentences in each year\n",
    "topics = df['keyword'].value_counts()\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671796b",
   "metadata": {},
   "source": [
    "# create a subset from all scenario types in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccacc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['humansc_tofinetune.xlsx', 'human_finetuned_gpt3_scenarios.xlsx', 'synthetic_scenarios.xlsx', 'syntheticscenariosGPT4.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a56326",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c939443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each CSV file: I want to have 2 scenarios from 2030, two from 2040 and 1 from 2050\n",
    "for file in files:\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # separate the scenarios by years\n",
    "    df_2030 = df[(df['year'] == 2030) & (df['keyword'] == 'science')]\n",
    "    df_2040 = df[(df['year'] == 2040) & (df['keyword'] == 'science')]\n",
    "    df_2050 = df[(df['year'] == 2050) & (df['keyword'] == 'science')]\n",
    "    \n",
    "    num_2030_sentences = 2\n",
    "    num_2040_sentences = 2\n",
    "    num_2050_sentences = 1\n",
    "    \n",
    "    # sample the scenarios for each specified year\n",
    "    subset_2030 = df_2030.sample(n=num_2030_sentences, replace=False, random_state=19)[['year', 'scenario']]\n",
    "    subset_2040 = df_2040.sample(n=num_2040_sentences, replace=False, random_state=19)[['year', 'scenario']]\n",
    "    subset_2050 = df_2050.sample(n=num_2050_sentences, replace=False, random_state=19)[['year', 'scenario']]\n",
    "    \n",
    "    # concatenate the subsets of different years\n",
    "    subset = pd.concat([subset_2030, subset_2040, subset_2050], axis=0, ignore_index=True)\n",
    "\n",
    "    # add the source column with the current file name\n",
    "    subset['source'] = file\n",
    "    \n",
    "    # add the subset of sentences to the list\n",
    "    subsets.append(subset)\n",
    "\n",
    "# combine the subsets of sentences into a single DataFrame\n",
    "combined_df = pd.concat(subsets, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the subsets of sentences into a single DataFrame\n",
    "combined_df = pd.concat(subsets, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "combined_df.to_excel('delphidata.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c92f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
